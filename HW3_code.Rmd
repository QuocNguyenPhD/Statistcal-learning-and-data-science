---
title: "Connor Nguyen(UHid: 1787501)"
output: html_notebook
---

# Homework 3

## Conceptual Question

### Question 1:

#### a)

```{r}

x1= c(1,0,0)
x2=c(1,-1,1)
plot(x1,x2)
curve(1*x,-2,2, add = T)
```

From the plot we can see that for the first data point is not classified . Let

$$
X_{1}-X_{2}<0
$$

be of color red and

$$
X_{1}-X_{2}>0
$$\
be of color blue

test for the first data point (1,1), X1-X2=0 => can not be determined

for the second data point (0,-1), X1-X2=1 => Blue

for the third data point (0,1), X1-X2=-1 => Red

#### b)

```{r}
x1=c(1,-1,1)
x2=c(1,-1,-1)
plot(x1,x2)
curve(-x,-2,2,add = T)
```

from the plot, we can see that the third data point is not determined. let

$$
X_{1}+X_{2}<0
$$

be Red;

$$
X_{1}+X_{2}>0
$$

be blue. we will get for the data point (1,1) will be blue; (-1,-1) will be red and (1,-1) will not be determined.

### Question 2:

#### a)

```{r}
library(plotrix)
plot(-8:10,-8:10,type="n")
draw.circle(-1,2,2)
draw.circle(-1,2,4)
```

#### b)

from the plot above, the set of point that has the property

$$
(1+X_1)^2+(2-X_2)^2>16
$$

will be outside of the larger circle. Whereas

$$
16 \ge (1+X_1)^2+(2-X_2)^2\ge 4
$$

the region will be outside of the smaller circle and inside of the bigger circle.

$$
(1+X_1)^2+(2-X_2)^2<4
$$

will be the region inside the smaller circle.

#### c)

(0,0) will be Red

(2,2) will be Blue

(3,4) will be Red

#### d)

consider

$$
 16 \ge (1+X_1)^2+(2-X_2)^2 \ge 4
$$

$$
16\ge X_1^2+X_2^2+2*X_1-4*X_2+5 \ge 4
$$

if we let X1^2^ =Y1 and X2^2^= Y2 then we have 4 variable where each of then is linear.

### Question 3:

#### a)

```{r}
x1=c(1,3,4,2,4,4,1,1)
x2=c(4,4,3,2,2,4,2,1)
y=c('blue','red','red','blue','red','red','blue','blue')
plot(x1, x2, col= y)
```

#### b), d)

```{r}
x1=c(1,3,4,2,4,4,1,1)
x2=c(4,4,3,2,2,4,2,1)
y=c('blue','red','red','blue','red','red','blue','blue')
plot(x1, x2, col= y, xlim=c(0,5), ylim=c(0,5))
abline(6,-2, lty=2)
abline(10,-2, lty=2)
curve(-2*x+8,0,5,add = T)

```

the equation has the form of

$$
X_1+2*X_2-8=0
$$

#### c)

maximum margin is about 1unit.

$$
X_1 +2*X_2-8< 0
$$

are blue and

$$
X_1+2*X_2-8>0
$$

are red

#### e)

support vector are (2,2);(1,4);(4,2); (3,4)

#### f)

vector 7th has the coordinate as (1,2). Since the 7th vector is not a support vector, changing slightly in the coordinate will not contribute to any change in the support vector. Hence, there will be no change.

#### g)

```{r}
x1=c(1,3,4,2,4,4,1,1)
x2=c(4,4,3,2,2,4,2,1)
y=c('blue','red','red','blue','red','red','blue','blue')
plot(x1, x2, col= y, xlim=c(0,5), ylim=c(0,5))

curve(-x+5,0,5, add=T)
```

#### h)

```{r}
x1=c(1,3,4,2,4,4,1,1)
x2=c(4,4,3,2,2,4,2,1)
y=c('blue','red','red','blue','red','red','blue','blue')
plot(x1, x2, col= y, xlim=c(0,5), ylim=c(0,5))
points(1,3,col= 'red')
```

## Applied

### Question 4:

#### a)

```{r}
library(MASS)
data('Boston')
Boston$medv= ifelse(Boston$medv>median(Boston$medv),1,0)
```

#### b)

Here, I will choose k=3, k=5, k=7 for the KNN method.

```{r}
cor(Boston[-14], Boston$medv)
```

the three strong predictor are lstat, rm, age since the correlation is the strongest from the data above.

correlation matrix:

```{r}
cor(Boston)
```

First model: all of the viable above

Second model: will include lstat, rm, age as the predictor

third model: Lstat, rm, age, indus

#### c)

leave one out and k fold cross validation is the more stable method.

k=3, model 1. Error rate is about 16%

```{r}
library(ISLR)
library(class)
knn.cv.prep=knn.cv(train= Boston[,-14], cl = Boston$medv, k=3)
mean(knn.cv.prep!=Boston$medv)
```

k=5, model 1. Error rate is about 18%

```{r}
knn.cv.prep=knn.cv(train= Boston[,-14], cl = Boston$medv, k=5)
mean(knn.cv.prep!=Boston$medv)
```

k=7, model 1. The error rate is about 19%

```{r}
knn.cv.prep=knn.cv(train= Boston[,-14], cl = Boston$medv, k=7)
mean(knn.cv.prep!=Boston$medv)
```

k=3, model 2. The error rate is about 20%

```{r}
knn.cv.prep=knn.cv(train= Boston[,c(6,7,13)], cl = Boston$medv, k=3)
mean(knn.cv.prep!=Boston$medv)
```

k=5, model 2. The error rate is about 19.6%

```{r}
knn.cv.prep=knn.cv(train= Boston[,c(6,7,13)], cl = Boston$medv, k=5)
mean(knn.cv.prep!=Boston$medv)
```

k=7, model 2. error rate is about 19.8%

```{r}
knn.cv.prep=knn.cv(train= Boston[,c(6,7,13)], cl = Boston$medv, k=7)
mean(knn.cv.prep!=Boston$medv)
```

k=3, model 3. The error rate is about 20%

```{r}
knn.cv.prep=knn.cv(train= Boston[,c(3,6,7,13)], cl = Boston$medv, k=3)
mean(knn.cv.prep!=Boston$medv)
```

k=5, model 3. the error rate is about 20.2%

```{r}
knn.cv.prep=knn.cv(train= Boston[,c(3,6,7,13)], cl = Boston$medv, k=5)
mean(knn.cv.prep!=Boston$medv)
```

k=7, model 3. The error rate is about 19.4%

```{r}
knn.cv.prep=knn.cv(train= Boston[,c(3,6,7,13)], cl = Boston$medv, k=7)
mean(knn.cv.prep!=Boston$medv)
```

all data with k=3 seem to outperform all the other method

#### d)

the data is not to scale with each other.

to fix this problem, we can split the data up into k fold. Then, normalize all of the testing data. Then use the normalized number of testing data to scale the training data

since we use the Leave one out cross validation, it is ok to just normalize everything in the beginning.

#### e)

```{r}
question4e=scale(Boston[-14])
knn.cv.prep=knn.cv(train= question4e, cl =Boston$medv , k=3)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e, cl =Boston$medv , k=5)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e, cl =Boston$medv , k=7)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e[,c(6,7,13)], cl =Boston$medv , k=3)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e[,c(6,7,13)], cl =Boston$medv , k=5)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e[,c(6,7,13)], cl =Boston$medv , k=7)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e[,c(3,6,7,13)], cl =Boston$medv , k=3)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e[,c(3,6,7,13)], cl =Boston$medv , k=5)
mean(knn.cv.prep!=Boston$medv)
knn.cv.prep=knn.cv(train= question4e[,c(3,6,7,13)], cl =Boston$medv , k=7)
mean(knn.cv.prep!=Boston$medv)
```

the lowest is when k=3 of all data. Now, the error rate seem more convincing.

### question 5:

#### a)

```{r}
Auto
Auto$mpg= ifelse(Auto$mpg>median(Auto$mpg),1,0)
Auto$name= NULL
```

#### b)

```{r}
set.seed(1)
library(e1071)
tune.out=tune(method=svm,
              train.y = Auto[1], train.x = Auto[-1],
              kernel="linear",
              ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
```

#### c)

the best performance is when the cost is 10^-2^

```{r}
bestmod=tune.out$best.model
```

```{r}
Auto.data=Auto[,-1]
predict.data= (predict(bestmod,Auto.data))
table(predict.data, Auto[1])
```

There are 2 type of error: true negative and false positive. These errors frequency is depend on the data and the model of prediction.

I give up with the code. could not fix it.

#### d)

```{r}
plot(bestmod,Auto[-1],Auto[1]~Auto[2])
```

### Question 6:

#### a)

```{r}
library(ISLR)
OJ
set.seed(1)
train= sample(1:1070, 800)
```

#### b)

purchase as respond and the other variable is the predictor.

```{r}
library(e1071)
OJ$Purchase=unclass(OJ$Purchase)
OJ$Store7=NULL
OJ$StoreID=NULL
svm.prep=svm(OJ[-1],OJ[1], cost = 0.01, type = 'C-classification')
summary(svm.prep)
```

classification model is based on 836 support vector with the cost of about 0.01

#### c)

```{r}
summary(tune(method = svm, train.y = OJ[train,1], train.x = OJ[train,-1],
              kernel="linear",
              cost= 0.01))
```

training error is about 0.1338969

```{r}
prediction=OJ[-train,-1]
prediction= predict( svm.prep ,prediction)
mean(prediction!=OJ[-train,1])

```

the testing error is about 37.78%

#### d)

```{r}
tune.error=tune(method=svm,
              train.y = OJ[train,1], train.x = OJ[train,-1],
              kernel="linear",
              ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10)))
summary(tune.error)

```

here the best training error is when the cost is about 10^-2^

#### e)

using the cost of 10^-2^ model will yield the result as in part C above, since the cost is the same
